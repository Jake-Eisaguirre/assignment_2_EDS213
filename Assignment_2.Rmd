---
title: "assignment_2"
author: "Jake Eisaguirre"
date: "10/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)


library(here)
library(tidyverse)
library(dataRetrieval)
library(patchwork)
library(lubridate)
```

# River Stuff

```{r}
discharge <- readNWISdv(
  siteNumber <- c("11118500", "11113500"),
parameterCd <- "00060",  # Discharge
startDate <- "1988-10-01", 
endDate <- "2018-09-30"
)

#In order to pull multiple sites I created a vector of the site numbers I wanted to pull. Both sites were the included in the downloaded data set.
  
ven_dis <- discharge %>% 
  filter(site_no == "11118500")

paul_dis <- discharge %>% 
  filter(site_no == "11113500")

a <- ggplot(ven_dis, aes(x = Date, y = X_00060_00003)) + 
  geom_line(col = "blue") +
  theme_classic() +
  labs(title = "Ventura" ) +
  ylab("Discharge cm^3/s")

b <- ggplot(paul_dis, aes(x = Date, y = X_00060_00003)) + 
  geom_line(col = "red") +
  theme_classic() +
  labs(title = "Santa Paula" ) +
  ylab("Discharge cm^3/s")

a/b
```
```{r}

startdate = as.Date("2021-10-04T00:00")
enddate = as.Date("2021-10-05T24:00")

c_dis <- readNWISuv(
  siteNumber = c("11118500", "11113500"), parameterCd = "00060", 
  startDate = startdate, endDate = enddate,
  tz = "PST")

n_v <- c_dis %>% 
  filter(site_no == "11118500")

j <- ggplot(n_v, aes(x = dateTime, y =X_00060_00000)) +
  geom_line() +
  theme_classic() +
  labs(title = "Ventura River 10/04/21-10/05/21" ) +
  ylab("Discharge cm^3/s") +
  xlab("Date")

n_c <- c_dis %>% 
  filter(site_no == "11113500")

k <- ggplot(n_c, aes(x = dateTime, y = X_00060_00000)) +
  geom_line() +
  theme_classic() +
  labs(title = "Santa Paula River 10/04/21-10/05/21" ) +
  ylab("Discharge cm^3/s") +
  xlab("Date")

j/k


#It looks like peak flow occurred for the Santa Paula river at 3 am and about 12:30 am for the Ventura river. However I would say there was not much of a peak for Ventura as discharge seems to oscillate between night a day. 


# Below is my over complicated code to look for peak flow between the rivers. I uderstand date formate better though.

# c_ven_dis <- c_dis %>% 
#   mutate(dateTime = ymd_hms( dateTime, tz = "PST")) %>%  #parse_date_time(dateTime, orders = "ymd HMS", tz = "PST")) %>% 
#   filter(site_no == "11118500") %>% 
#   group_by(day = day(dateTime), hour = hour(dateTime)) %>% 
#   unite("day_hour", day:hour, sep = "-") %>% 
#   group_by(day_hour) %>% 
#   summarise(mean_hour = mean(X_00060_00000)) 
#  
# 
# c_paul_dis <- c_dis %>%
#  mutate(dateTime = ymd_hms( dateTime, tz = "PST")) %>% 
#   filter(site_no == "11113500") %>% 
#   group_by(day = day(dateTime), hour = hour(dateTime)) %>% 
#   unite("day_hour", day:hour, sep = "-") %>% 
#   group_by(day_hour) %>% 
#   summarise(mean_hour = mean(X_00060_00000)) 
# 
# 
# c <- ggplot(c_ven_dis, aes(x = day_hour, y = mean_hour)) + 
#   geom_point(col = "blue") +
#   theme_classic() +
#   labs(title = "Ventura River 10/04/21" ) +
#   ylab("Discharge cm^3/s") +
#   xlab("Hourly Mean") +
#   theme(axis.text.x = element_text(angle = 90))
# 
# c
# 
# 
# d <- ggplot(c_paul_dis, aes(x = day_hour, y = mean_hour)) + 
#   geom_point(col = "red") +
#   theme_classic() +
#   labs(title = "Santa Paula 10/04/21" ) +
#   ylab("Discharge cm^3/s") +
#   xlab("Hourly Mean") +
#   theme(axis.text.x = element_text(angle = 90))
# 
# c/d


```
# Alaska Stuff

```{r}

data_url = "https://knb.ecoinformatics.org/knb/d1/mn/v2/object/urn%3Auuid%3A7fc6f6db-c5ea-426a-a743-1f2edafb43b8"

path = ("/Users/JaketheBoss/Documents/Bren/fall_courses/EDS_213/assignment_2_EDS213")
library(metajam)
data_path = download_d1_data(data_url, path)

data <- read_csv(here("Data", "household_language.csv"))

p_lang <- data %>% 
  filter(Year >= 2009,
         Year <= 2015) %>% 
  group_by(Year = Year) %>% 
  summarize(p_e = sum(speak_only_english)/sum(total)*100) %>% 
  summarise(Year, p_e)

ggplot(data = p_lang, aes(x = Year, y = p_e))+
  geom_line() +
  theme_classic() +
  ylab("Percent") +
  labs(title = "AK Residents Who Only Speak English 2009-2015") +
  geom_point()


```

